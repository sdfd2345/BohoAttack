task: 'UVvolume_CMU'
gpus: [2]

train_dataset_module: 'lib.datasets.dataset'
train_dataset_path: 'lib/datasets/dataset.py'
test_dataset_module: 'lib.datasets.dataset'
test_dataset_path: 'lib/datasets/dataset.py'

network_module: 'lib.networks.nts'
network_path: 'lib/networks/nts.py'
renderer_module: 'lib.networks.renderer.uv_volumes'
renderer_path: 'lib/networks/renderer/uv_volumes.py'

trainer_module: 'lib.train.trainers.loss_function'
trainer_path: 'lib/train/trainers/loss_function.py'

evaluator_module: 'lib.evaluators.evaluator'
evaluator_path: 'lib/evaluators/evaluator.py'

train_dataset:
    data_root: 'data/cmu_panoptic/171204_pose4_sample6'
    human: 'cmu_panoptic'
    ann_file: 'data/cmu_panoptic/171204_pose4_sample6/annots.npy'
    split: 'train'

test_dataset:
    data_root: 'data/cmu_panoptic/171204_pose4_sample6'
    human: 'cmu_panoptic'
    ann_file: 'data/cmu_panoptic/171204_pose4_sample6/annots.npy'
    split: 'test'

train:
    batch_size: 1
    collator: ''
    lr: 5e-4
    weight_decay: 0
    epoch: 600
    scheduler:
        type: 'exponential_two_part'
        gamma: 0.1
        decay_epochs1: 1000
        decay_epochs2: 250
    num_workers: 16

test:
    sampler: 'FrameSampler'
    batch_size: 1
    collator: ''
 
ep_iter: 500
save_ep: 50
eval_ep: 50

# rendering options
i_embed: 0
xyz_res: 10
view_res: 4
i_res: 4
raw_noise_std: 0

N_samples: 64
N_importance: 128
N_rand: 1024

perturb: 1
white_bkgd: False

# data options
H: 1080
W: 1920
ratio: 0.5
training_view: [0, 2, 3,4, 5,6, 8, 9,10, 11,12, 13,14, 15,16, 17,18, 19,20,22,23, 24, 25,26, 27]
test_view: [1, 7, 21, 28]
num_train_frame: 100
begin_ith_frame: 780
frame_interval: 1
params: 'params_smplx'
vertices: 'vertices_smplx'
densepose: 'densepose'
mask: 'mask_cihp'
mask_threshold: 0.1
nv: 10475
pose_dim: 87
box_padding: 0.1

voxel_size: [0.005, 0.005, 0.005]  # dhw
